{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42218ab6",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Python\n",
    "\n",
    "Natural Language Processing (NLP) is a field of computer science that focuses on the interaction between computers and humans through natural language. The ultimate objective of NLP is to enable computers to understand, interpret, and generate human language in a way that is valuable.\n",
    "\n",
    "Although NLP includes a wide range of techniques and applications, some of the most common tasks include:\n",
    "\n",
    "1. **Tokenization**: Breaking down text into smaller units, such as words or sentences.\n",
    "2. **Lowercasing**: Converting all characters in the text to lowercase to ensure uniformity.\n",
    "3. **Lemmatization**: Reducing words to their base or root form:\n",
    "   - Example: \"running\" becomes \"run\"\n",
    "   - Example: \"tasks\" becomes \"task\"\n",
    "4. **Special Character Removal**: Stripping out punctuation, numbers, and other non-alphabetic characters from the text.\n",
    "5. **Stopword Removal**: Eliminating common words (e.g., \"the\", \"is\", \"and\") that do not contribute significantly to the meaning of the text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b94c90",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "`spaCy` is a NLP library in Python that provides tools for tokenization, lemmatization, and more. You may have used `nltk` or `textblob` before, but `spaCy` is known for its speed and efficiency. For small tasks like this, you will not notice much difference, but for larger datasets, `spaCy` can be significantly faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf03c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7defceb",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this tutorial, we will use a dataset of Glassdoor reviews for MasterCard. The dataset contains employee reviews about their experiences working at MasterCard, including pros and cons of the company.\n",
    "\n",
    "Some reviews may contain special characters, mixed casing, and stopwords, which we will clean using the NLP techniques mentioned above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dacb55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_liked_text</th>\n",
       "      <th>review_disliked_text</th>\n",
       "      <th>count_helpful</th>\n",
       "      <th>count_not_helpful</th>\n",
       "      <th>employer_responses</th>\n",
       "      <th>is_current_job</th>\n",
       "      <th>length_of_employment</th>\n",
       "      <th>...</th>\n",
       "      <th>rating_ceo</th>\n",
       "      <th>rating_compensation_and_benefits</th>\n",
       "      <th>rating_culture_and_values</th>\n",
       "      <th>rating_diversity_and_inclusion</th>\n",
       "      <th>rating_overall</th>\n",
       "      <th>rating_recommend_to_friend</th>\n",
       "      <th>rating_senior_leadership</th>\n",
       "      <th>rating_work_life_balance</th>\n",
       "      <th>job_title_text</th>\n",
       "      <th>location_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101108831</td>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>no</td>\n",
       "      <td>surroundings is very awesome and good</td>\n",
       "      <td>only the people who is master</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>APPROVE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101220670</td>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>Continue nurturing the supportive culture and ...</td>\n",
       "      <td>Celebrating 10 years with Mastercard has been ...</td>\n",
       "      <td>Like any fast-growing company, there have been...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>APPROVE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Principal Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100991760</td>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working in Business experimentation is extreme...</td>\n",
       "      <td>The pay is not competitive compared with other...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>APPROVE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>Arlington, VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id review_date                                        review_text  \\\n",
       "0  101108831  2025-11-06                                                 no   \n",
       "1  101220670  2025-11-11  Continue nurturing the supportive culture and ...   \n",
       "2  100991760  2025-10-30                                                NaN   \n",
       "\n",
       "                                   review_liked_text  \\\n",
       "0              surroundings is very awesome and good   \n",
       "1  Celebrating 10 years with Mastercard has been ...   \n",
       "2  Working in Business experimentation is extreme...   \n",
       "\n",
       "                                review_disliked_text  count_helpful  \\\n",
       "0                      only the people who is master              0   \n",
       "1  Like any fast-growing company, there have been...              0   \n",
       "2  The pay is not competitive compared with other...              0   \n",
       "\n",
       "   count_not_helpful employer_responses  is_current_job  length_of_employment  \\\n",
       "0                  0                NaN            True                     2   \n",
       "1                  0                NaN            True                    20   \n",
       "2                  0                NaN            True                     0   \n",
       "\n",
       "   ... rating_ceo  rating_compensation_and_benefits rating_culture_and_values  \\\n",
       "0  ...    APPROVE                               5.0                         5   \n",
       "1  ...    APPROVE                               3.0                         5   \n",
       "2  ...    APPROVE                               4.0                         5   \n",
       "\n",
       "   rating_diversity_and_inclusion  rating_overall  rating_recommend_to_friend  \\\n",
       "0                               5               5                    POSITIVE   \n",
       "1                               5               4                    POSITIVE   \n",
       "2                               5               4                    POSITIVE   \n",
       "\n",
       "   rating_senior_leadership rating_work_life_balance      job_title_text  \\\n",
       "0                       5.0                      5.0     Human Resources   \n",
       "1                       5.0                      4.0  Principal Engineer   \n",
       "2                       3.0                      3.0          Consultant   \n",
       "\n",
       "   location_name  \n",
       "0   New York, NY  \n",
       "1   New York, NY  \n",
       "2  Arlington, VA  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/bdi475/datasets/refs/heads/main/mastercard-glassdoor-reviews.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3485f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 22 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   review_id                         1000 non-null   int64  \n",
      " 1   review_date                       1000 non-null   object \n",
      " 2   review_text                       389 non-null    object \n",
      " 3   review_liked_text                 1000 non-null   object \n",
      " 4   review_disliked_text              1000 non-null   object \n",
      " 5   count_helpful                     1000 non-null   int64  \n",
      " 6   count_not_helpful                 1000 non-null   int64  \n",
      " 7   employer_responses                38 non-null     object \n",
      " 8   is_current_job                    1000 non-null   bool   \n",
      " 9   length_of_employment              1000 non-null   int64  \n",
      " 10  rating_business_outlook           661 non-null    object \n",
      " 11  rating_career_opportunities       1000 non-null   float64\n",
      " 12  rating_ceo                        685 non-null    object \n",
      " 13  rating_compensation_and_benefits  1000 non-null   float64\n",
      " 14  rating_culture_and_values         1000 non-null   int64  \n",
      " 15  rating_diversity_and_inclusion    1000 non-null   int64  \n",
      " 16  rating_overall                    1000 non-null   int64  \n",
      " 17  rating_recommend_to_friend        714 non-null    object \n",
      " 18  rating_senior_leadership          1000 non-null   float64\n",
      " 19  rating_work_life_balance          1000 non-null   float64\n",
      " 20  job_title_text                    871 non-null    object \n",
      " 21  location_name                     803 non-null    object \n",
      "dtypes: bool(1), float64(4), int64(7), object(10)\n",
      "memory usage: 165.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57db564a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location_name\n",
       "New York, NY          174\n",
       "Purchase, NY          140\n",
       "O'Fallon, MO          139\n",
       "Saint Louis, MO       110\n",
       "Arlington, VA          67\n",
       "San Francisco, CA      23\n",
       "Miami, FL              22\n",
       "O Fallon, MO           22\n",
       "Washington, DC         11\n",
       "Salt Lake City, UT     10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"location_name\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b926cc",
   "metadata": {},
   "source": [
    "## NLP with `spaCy` using a String\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d7f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy English model\n",
    "# Make sure you've run: python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e253c04",
   "metadata": {},
   "source": [
    "Here is a sample text that we will process using `spaCy`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d418ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = \"Celebrating 10 years with Mastercard has been an incredible journey - great benefits, flexible hours, and amazing colleagues!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8396ae",
   "metadata": {},
   "source": [
    "A `nlp` object is created using the `spacy.load()` function, which loads a pre-trained language model. In this case, we are using the English model `en_core_web_sm`. The text is then processed using the `nlp()` function, which creates a `Doc` object containing tokens and their linguistic features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf94d631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a spaCy Doc\n",
    "doc = nlp(original_text)\n",
    "\n",
    "# Check the type of doc\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8eee2d",
   "metadata": {},
   "source": [
    "We can tokenize the text, convert it to lowercase, lemmatize the tokens, remove special characters, and eliminate stopwords. Although this tutorial intentionally breaks down each step for clarity, in practice, these steps can be combined into a single processing pipeline for efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744074d8",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Tokenization is the process of breaking down text into smaller units called tokens, which can be words, phrases, or symbols. In this case, we are tokenizing the text using spaCy's `Doc` object, which allows us to easily access and manipulate the tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f64caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Celebrating', '10', 'years', 'with', 'Mastercard']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9dab9",
   "metadata": {},
   "source": [
    "### Lowercasing\n",
    "\n",
    "We convert all tokens to lowercase to ensure uniformity. This helps in reducing the number of unique tokens, as \"The\" and \"the\" will be treated as the same token. Note that we are using Python's built-in `lower()` method for strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0beb2840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['celebrating', '10', 'years', 'with', 'mastercard']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercasing\n",
    "lower_tokens = [t.lower() for t in tokens]\n",
    "\n",
    "lower_tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff328721",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization is the process of reducing words to their base or root form, known as the lemma. This helps in normalizing words and reducing the number of unique tokens. For example, \"running\" becomes \"run\", and \"tasks\" becomes \"task\". In this case, we are using spaCy's built-in lemmatization capabilities to obtain the lemmas of the tokens.\n",
    "\n",
    "The `lemma_` attribute of each token in the `Doc` object provides the lemmatized form of the token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f68fe5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['celebrate', '10', 'year', 'with', 'Mastercard']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "lemmas[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d5392f",
   "metadata": {},
   "source": [
    ":::{warning} This step is redundant!\n",
    "\n",
    "The stop word removal that comes later also converts tokens to lowercase, so this step is redundant. This is only included here for educational purposes to illustrate the lowercasing process separately.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a705790",
   "metadata": {},
   "source": [
    "### Stopword Removal\n",
    "\n",
    "Stopwords are common words that do not contribute significantly to the meaning of the text. Examples include \"the\", \"is\", \"and\", etc. Removing stopwords helps in reducing noise and focusing on the more meaningful words in the text.\n",
    "\n",
    "`spaCy` provides a built-in attribute `is_stop` for each token, which indicates whether the token is a stopword. We can use this attribute to filter out stopwords from our list of tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f10c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['celebrate', '10', 'year', 'mastercard', 'incredible']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopword & punctuation removal (lemmatized + lowercased)\n",
    "clean_tokens = [\n",
    "    token.lemma_.lower()\n",
    "    for token in doc\n",
    "    if not token.is_stop and not token.is_punct and not token.is_space\n",
    "]\n",
    "clean_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65f682ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Celebrating 10 years with Mastercard has been an incredible journey - great benefits, flexible hours, and amazing colleagues!\n",
      "Tokens: ['Celebrating', '10', 'years', 'with', 'Mastercard', 'has', 'been', 'an', 'incredible', 'journey', '-', 'great', 'benefits', ',', 'flexible', 'hours', ',', 'and', 'amazing', 'colleagues', '!']\n",
      "Lower tokens: ['celebrating', '10', 'years', 'with', 'mastercard', 'has', 'been', 'an', 'incredible', 'journey', '-', 'great', 'benefits', ',', 'flexible', 'hours', ',', 'and', 'amazing', 'colleagues', '!']\n",
      "Lemmas: ['celebrate', '10', 'year', 'with', 'Mastercard', 'have', 'be', 'an', 'incredible', 'journey', '-', 'great', 'benefit', ',', 'flexible', 'hour', ',', 'and', 'amazing', 'colleague', '!']\n",
      "Clean tokens (no stopwords/punct, lemmatized, lowercased): ['celebrate', '10', 'year', 'mastercard', 'incredible', 'journey', 'great', 'benefit', 'flexible', 'hour', 'amazing', 'colleague']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\", original_text)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Lower tokens:\", lower_tokens)\n",
    "print(\"Lemmas:\", lemmas)\n",
    "print(\"Clean tokens (no stopwords/punct, lemmatized, lowercased):\", clean_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80efe259",
   "metadata": {},
   "source": [
    "## NLP with `spaCy` using a `DataFrame`\n",
    "\n",
    "We can apply the same NLP techniques to a pandas `DataFrame` containing multiple reviews. We will process the \"liked\" column of the DataFrame, which contains employee reviews about what they liked about working at MasterCard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e9653",
   "metadata": {},
   "source": [
    "The dataset we're working with has 1000 reviews in total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25d34a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 22)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e9c7eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_liked_text</th>\n",
       "      <th>liked_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101108831</td>\n",
       "      <td>surroundings is very awesome and good</td>\n",
       "      <td>[surrounding, awesome, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101220670</td>\n",
       "      <td>Celebrating 10 years with Mastercard has been ...</td>\n",
       "      <td>[celebrate, 10, year, mastercard, incredible, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100991760</td>\n",
       "      <td>Working in Business experimentation is extreme...</td>\n",
       "      <td>[work, business, experimentation, extremely, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100092071</td>\n",
       "      <td>Benefits such as 401k, sick leave, etc</td>\n",
       "      <td>[benefit, 401k, sick, leave, etc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100155384</td>\n",
       "      <td>The logo. The stock price. The ability to tell...</td>\n",
       "      <td>[logo, stock, price, ability, tell, people, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                  review_liked_text  \\\n",
       "0  101108831              surroundings is very awesome and good   \n",
       "1  101220670  Celebrating 10 years with Mastercard has been ...   \n",
       "2  100991760  Working in Business experimentation is extreme...   \n",
       "3  100092071             Benefits such as 401k, sick leave, etc   \n",
       "4  100155384  The logo. The stock price. The ability to tell...   \n",
       "\n",
       "                                        liked_tokens  \n",
       "0                       [surrounding, awesome, good]  \n",
       "1  [celebrate, 10, year, mastercard, incredible, ...  \n",
       "2  [work, business, experimentation, extremely, r...  \n",
       "3                  [benefit, 401k, sick, leave, etc]  \n",
       "4  [logo, stock, price, ability, tell, people, pa...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize \"review_liked_text\" using the already-loaded spaCy `nlp`\n",
    "texts = df[\"review_liked_text\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Use nlp.pipe for efficiency and disable unused components\n",
    "token_lists = []\n",
    "for doc in nlp.pipe(texts, disable=[\"parser\", \"ner\"]):\n",
    "    token_lists.append(\n",
    "        [\n",
    "            token.lemma_.lower()\n",
    "            for token in doc\n",
    "            if not token.is_stop and not token.is_punct and not token.is_space\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Create new DataFrame with review_id, original text, and token list\n",
    "df_tokens = pd.DataFrame({\n",
    "    \"review_id\": df[\"review_id\"].values,\n",
    "    \"review_liked_text\": texts.values,\n",
    "    \"liked_tokens\": token_lists\n",
    "})\n",
    "\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5738e222",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_liked_text</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101108831</td>\n",
       "      <td>surroundings is very awesome and good</td>\n",
       "      <td>surrounding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101108831</td>\n",
       "      <td>surroundings is very awesome and good</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101108831</td>\n",
       "      <td>surroundings is very awesome and good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101220670</td>\n",
       "      <td>Celebrating 10 years with Mastercard has been ...</td>\n",
       "      <td>celebrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101220670</td>\n",
       "      <td>Celebrating 10 years with Mastercard has been ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                  review_liked_text        token\n",
       "0  101108831              surroundings is very awesome and good  surrounding\n",
       "1  101108831              surroundings is very awesome and good      awesome\n",
       "2  101108831              surroundings is very awesome and good         good\n",
       "3  101220670  Celebrating 10 years with Mastercard has been ...    celebrate\n",
       "4  101220670  Celebrating 10 years with Mastercard has been ...           10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explode liked_tokens so each token becomes its own row\n",
    "df_liked_exploded = df_tokens.explode(\"liked_tokens\").reset_index(drop=True)\n",
    "df_liked_exploded = df_liked_exploded.rename(columns={\"liked_tokens\": \"token\"})\n",
    "\n",
    "# Clean: drop missing/empty tokens and trim whitespace\n",
    "df_liked_exploded[\"token\"] = df_liked_exploded[\"token\"].str.strip()\n",
    "df_liked_exploded = df_liked_exploded[df_liked_exploded[\"token\"] != \"\"]\n",
    "\n",
    "# Inspect result\n",
    "df_liked_exploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656a36a",
   "metadata": {},
   "source": [
    "After processing the \"liked\" column, we explode the list of tokens so that each token becomes its own row in the DataFrame. We also clean the tokens by dropping any missing or empty tokens and trimming whitespace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25c4de25",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12919, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_exploded.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
