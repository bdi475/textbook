{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42218ab6",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Python\n",
    "\n",
    "Natural Language Processing (NLP) is a field of computer science that focuses on the interaction between computers and humans through natural language. The ultimate objective of NLP is to enable computers to understand, interpret, and generate human language in a way that is valuable.\n",
    "\n",
    "Although NLP includes a wide range of techniques and applications, some of the most common tasks include:\n",
    "\n",
    "1. **Tokenization**: Breaking down text into smaller units, such as words or sentences.\n",
    "2. **Lowercasing**: Converting all characters in the text to lowercase to ensure uniformity.\n",
    "3. **Lemmatization**: Reducing words to their base or root form:\n",
    "   - Example: \"running\" becomes \"run\"\n",
    "   - Example: \"tasks\" becomes \"task\"\n",
    "4. **Special Character Removal**: Stripping out punctuation, numbers, and other non-alphabetic characters from the text.\n",
    "5. **Stopword Removal**: Eliminating common words (e.g., \"the\", \"is\", \"and\") that do not contribute significantly to the meaning of the text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b94c90",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "`spaCy` is a NLP library in Python that provides tools for tokenization, lemmatization, and more. You may have used `nltk` or `textblob` before, but `spaCy` is known for its speed and efficiency. For small tasks like this, you will not notice much difference, but for larger datasets, `spaCy` can be significantly faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf03c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b926cc",
   "metadata": {},
   "source": [
    "## NLP with `spaCy` using a String\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01d7f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy English model\n",
    "# Make sure you've run: python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e253c04",
   "metadata": {},
   "source": [
    "Here is a sample text that we will process using `spaCy`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d418ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = \"Celebrating 10 years with Mastercard has been an incredible journey - great benefits, flexible hours, and amazing colleagues!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8396ae",
   "metadata": {},
   "source": [
    "A `nlp` object is created using the `spacy.load()` function, which loads a pre-trained language model. In this case, we are using the English model `en_core_web_sm`. The text is then processed using the `nlp()` function, which creates a `Doc` object containing tokens and their linguistic features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf94d631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a spaCy Doc\n",
    "doc = nlp(original_text)\n",
    "\n",
    "# Check the type of doc\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8eee2d",
   "metadata": {},
   "source": [
    "We can tokenize the text, convert it to lowercase, lemmatize the tokens, remove special characters, and eliminate stopwords. Although this tutorial intentionally breaks down each step for clarity, in practice, these steps can be combined into a single processing pipeline for efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744074d8",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Tokenization is the process of breaking down text into smaller units called tokens, which can be words, phrases, or symbols. In this case, we are tokenizing the text using spaCy's `Doc` object, which allows us to easily access and manipulate the tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f64caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Celebrating', '10', 'years', 'with', 'Mastercard']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9dab9",
   "metadata": {},
   "source": [
    "### Lowercasing\n",
    "\n",
    "We convert all tokens to lowercase to ensure uniformity. This helps in reducing the number of unique tokens, as \"The\" and \"the\" will be treated as the same token. Note that we are using Python's built-in `lower()` method for strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0beb2840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['celebrating', '10', 'years', 'with', 'mastercard']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercasing\n",
    "lower_tokens = [t.lower() for t in tokens]\n",
    "\n",
    "lower_tokens[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff328721",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization is the process of reducing words to their base or root form, known as the lemma. This helps in normalizing words and reducing the number of unique tokens. For example, \"running\" becomes \"run\", and \"tasks\" becomes \"task\". In this case, we are using spaCy's built-in lemmatization capabilities to obtain the lemmas of the tokens.\n",
    "\n",
    "The `lemma_` attribute of each token in the `Doc` object provides the lemmatized form of the token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f68fe5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['celebrate', '10', 'year', 'with', 'Mastercard']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "lemmas[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d5392f",
   "metadata": {},
   "source": [
    ":::{warning} This step is redundant!\n",
    "\n",
    "The stop word removal that comes later also converts tokens to lowercase, so this step is redundant. This is only included here for educational purposes to illustrate the lowercasing process separately.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a705790",
   "metadata": {},
   "source": [
    "### Stopword Removal\n",
    "\n",
    "Stopwords are common words that do not contribute significantly to the meaning of the text. Examples include \"the\", \"is\", \"and\", etc. Removing stopwords helps in reducing noise and focusing on the more meaningful words in the text.\n",
    "\n",
    "`spaCy` provides a built-in attribute `is_stop` for each token, which indicates whether the token is a stopword. We can use this attribute to filter out stopwords from our list of tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f10c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['celebrate', '10', 'year', 'mastercard', 'incredible']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopword & punctuation removal (lemmatized + lowercased)\n",
    "clean_tokens = [\n",
    "    token.lemma_.lower()\n",
    "    for token in doc\n",
    "    if not token.is_stop and not token.is_punct and not token.is_space\n",
    "]\n",
    "clean_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f682ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Celebrating 10 years with Mastercard has been an incredible journey - great benefits, flexible hours, and amazing colleagues!\n",
      "Tokens: ['Celebrating', '10', 'years', 'with', 'Mastercard', 'has', 'been', 'an', 'incredible', 'journey', '-', 'great', 'benefits', ',', 'flexible', 'hours', ',', 'and', 'amazing', 'colleagues', '!']\n",
      "Lower tokens: ['celebrating', '10', 'years', 'with', 'mastercard', 'has', 'been', 'an', 'incredible', 'journey', '-', 'great', 'benefits', ',', 'flexible', 'hours', ',', 'and', 'amazing', 'colleagues', '!']\n",
      "Lemmas: ['celebrate', '10', 'year', 'with', 'Mastercard', 'have', 'be', 'an', 'incredible', 'journey', '-', 'great', 'benefit', ',', 'flexible', 'hour', ',', 'and', 'amazing', 'colleague', '!']\n",
      "Clean tokens (no stopwords/punct, lemmatized, lowercased): ['celebrate', '10', 'year', 'mastercard', 'incredible', 'journey', 'great', 'benefit', 'flexible', 'hour', 'amazing', 'colleague']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\", original_text)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Lower tokens:\", lower_tokens)\n",
    "print(\"Lemmas:\", lemmas)\n",
    "print(\"Clean tokens (no stopwords/punct, lemmatized, lowercased):\", clean_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80efe259",
   "metadata": {},
   "source": [
    "## NLP with `spaCy` using a `DataFrame`\n",
    "\n",
    "We can apply the same NLP techniques to a pandas `DataFrame` containing multiple reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2d547",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset contains Glassdoor employee reviews for MasterCard. Each review has a unique `review_id` and multiple ratings and text fields. We will focus on the text fields, which contains text about what employees liked or disliked about working at MasterCard.\n",
    "\n",
    "Some reviews may contain special characters, mixed casing, and stopwords, which we will clean using the NLP techniques mentioned above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25fd138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_liked_text</th>\n",
       "      <th>review_disliked_text</th>\n",
       "      <th>count_helpful</th>\n",
       "      <th>count_not_helpful</th>\n",
       "      <th>employer_responses</th>\n",
       "      <th>is_current_job</th>\n",
       "      <th>length_of_employment</th>\n",
       "      <th>...</th>\n",
       "      <th>rating_ceo</th>\n",
       "      <th>rating_compensation_and_benefits</th>\n",
       "      <th>rating_culture_and_values</th>\n",
       "      <th>rating_diversity_and_inclusion</th>\n",
       "      <th>rating_overall</th>\n",
       "      <th>rating_recommend_to_friend</th>\n",
       "      <th>rating_senior_leadership</th>\n",
       "      <th>rating_work_life_balance</th>\n",
       "      <th>job_title_text</th>\n",
       "      <th>location_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101108831</td>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>no</td>\n",
       "      <td>surroundings is very awesome and good</td>\n",
       "      <td>only the people who is master</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>APPROVE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101220670</td>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>Continue nurturing the supportive culture and ...</td>\n",
       "      <td>Celebrating 10 years with Mastercard has been ...</td>\n",
       "      <td>Like any fast-growing company, there have been...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>APPROVE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Principal Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100991760</td>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working in Business experimentation is extreme...</td>\n",
       "      <td>The pay is not competitive compared with other...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>APPROVE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>Arlington, VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id review_date                                        review_text  \\\n",
       "0  101108831  2025-11-06                                                 no   \n",
       "1  101220670  2025-11-11  Continue nurturing the supportive culture and ...   \n",
       "2  100991760  2025-10-30                                                NaN   \n",
       "\n",
       "                                   review_liked_text  \\\n",
       "0              surroundings is very awesome and good   \n",
       "1  Celebrating 10 years with Mastercard has been ...   \n",
       "2  Working in Business experimentation is extreme...   \n",
       "\n",
       "                                review_disliked_text  count_helpful  \\\n",
       "0                      only the people who is master              0   \n",
       "1  Like any fast-growing company, there have been...              0   \n",
       "2  The pay is not competitive compared with other...              0   \n",
       "\n",
       "   count_not_helpful employer_responses  is_current_job  length_of_employment  \\\n",
       "0                  0                NaN            True                     2   \n",
       "1                  0                NaN            True                    20   \n",
       "2                  0                NaN            True                     0   \n",
       "\n",
       "   ... rating_ceo  rating_compensation_and_benefits rating_culture_and_values  \\\n",
       "0  ...    APPROVE                               5.0                         5   \n",
       "1  ...    APPROVE                               3.0                         5   \n",
       "2  ...    APPROVE                               4.0                         5   \n",
       "\n",
       "   rating_diversity_and_inclusion  rating_overall  rating_recommend_to_friend  \\\n",
       "0                               5               5                    POSITIVE   \n",
       "1                               5               4                    POSITIVE   \n",
       "2                               5               4                    POSITIVE   \n",
       "\n",
       "   rating_senior_leadership rating_work_life_balance      job_title_text  \\\n",
       "0                       5.0                      5.0     Human Resources   \n",
       "1                       5.0                      4.0  Principal Engineer   \n",
       "2                       3.0                      3.0          Consultant   \n",
       "\n",
       "   location_name  \n",
       "0   New York, NY  \n",
       "1   New York, NY  \n",
       "2  Arlington, VA  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/bdi475/datasets/refs/heads/main/mastercard-glassdoor-reviews.csv\"\n",
    ")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea14ba36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 22 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   review_id                         1000 non-null   int64  \n",
      " 1   review_date                       1000 non-null   object \n",
      " 2   review_text                       389 non-null    object \n",
      " 3   review_liked_text                 1000 non-null   object \n",
      " 4   review_disliked_text              1000 non-null   object \n",
      " 5   count_helpful                     1000 non-null   int64  \n",
      " 6   count_not_helpful                 1000 non-null   int64  \n",
      " 7   employer_responses                38 non-null     object \n",
      " 8   is_current_job                    1000 non-null   bool   \n",
      " 9   length_of_employment              1000 non-null   int64  \n",
      " 10  rating_business_outlook           661 non-null    object \n",
      " 11  rating_career_opportunities       1000 non-null   float64\n",
      " 12  rating_ceo                        685 non-null    object \n",
      " 13  rating_compensation_and_benefits  1000 non-null   float64\n",
      " 14  rating_culture_and_values         1000 non-null   int64  \n",
      " 15  rating_diversity_and_inclusion    1000 non-null   int64  \n",
      " 16  rating_overall                    1000 non-null   int64  \n",
      " 17  rating_recommend_to_friend        714 non-null    object \n",
      " 18  rating_senior_leadership          1000 non-null   float64\n",
      " 19  rating_work_life_balance          1000 non-null   float64\n",
      " 20  job_title_text                    871 non-null    object \n",
      " 21  location_name                     803 non-null    object \n",
      "dtypes: bool(1), float64(4), int64(7), object(10)\n",
      "memory usage: 165.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e9653",
   "metadata": {},
   "source": [
    "There are 1000 reviews in total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25d34a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a7de0",
   "metadata": {},
   "source": [
    "### What did employees like about working at MasterCard?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e9c7eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_liked_text</th>\n",
       "      <th>review_liked_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101108831</td>\n",
       "      <td>surroundings is very awesome and good</td>\n",
       "      <td>[surrounding, awesome, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101220670</td>\n",
       "      <td>Celebrating 10 years with Mastercard has been ...</td>\n",
       "      <td>[celebrate, 10, year, mastercard, incredible, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100991760</td>\n",
       "      <td>Working in Business experimentation is extreme...</td>\n",
       "      <td>[work, business, experimentation, extremely, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100092071</td>\n",
       "      <td>Benefits such as 401k, sick leave, etc</td>\n",
       "      <td>[benefit, 401k, sick, leave, etc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100155384</td>\n",
       "      <td>The logo. The stock price. The ability to tell...</td>\n",
       "      <td>[logo, stock, price, ability, tell, people, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                  review_liked_text  \\\n",
       "0  101108831              surroundings is very awesome and good   \n",
       "1  101220670  Celebrating 10 years with Mastercard has been ...   \n",
       "2  100991760  Working in Business experimentation is extreme...   \n",
       "3  100092071             Benefits such as 401k, sick leave, etc   \n",
       "4  100155384  The logo. The stock price. The ability to tell...   \n",
       "\n",
       "                                 review_liked_tokens  \n",
       "0                       [surrounding, awesome, good]  \n",
       "1  [celebrate, 10, year, mastercard, incredible, ...  \n",
       "2  [work, business, experimentation, extremely, r...  \n",
       "3                  [benefit, 401k, sick, leave, etc]  \n",
       "4  [logo, stock, price, ability, tell, people, pa...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lists = []\n",
    "\n",
    "# parser is the dependency parser\n",
    "# ner is the named entity recognizer\n",
    "for doc in nlp.pipe(df[\"review_liked_text\"], disable=[\"parser\", \"ner\"]):\n",
    "    token_lists.append(\n",
    "        [\n",
    "            token.lemma_.lower()\n",
    "            for token in doc\n",
    "            if not token.is_stop and not token.is_punct and not token.is_space\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df[\"review_liked_tokens\"] = token_lists\n",
    "\n",
    "df[[\"review_id\", \"review_liked_text\", \"review_liked_tokens\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5738e222",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101108831</td>\n",
       "      <td>surrounding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101108831</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101108831</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101220670</td>\n",
       "      <td>celebrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101220670</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id        token\n",
       "0  101108831  surrounding\n",
       "1  101108831      awesome\n",
       "2  101108831         good\n",
       "3  101220670    celebrate\n",
       "4  101220670           10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explode liked_tokens so each token becomes its own row\n",
    "df_liked_exploded = df[[\"review_id\", \"review_liked_tokens\"]].explode(\"review_liked_tokens\").reset_index(drop=True)\n",
    "df_liked_exploded = df_liked_exploded.rename(columns={\"review_liked_tokens\": \"token\"})\n",
    "\n",
    "# Inspect result\n",
    "df_liked_exploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656a36a",
   "metadata": {},
   "source": [
    "After processing the \"liked\" column, we explode the list of tokens so that each token becomes its own row in the DataFrame. We also clean the tokens by dropping any missing or empty tokens and trimming whitespace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25c4de25",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12919, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_exploded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe2cc38",
   "metadata": {},
   "source": [
    "The most common tokens in the \"liked\" reviews can be identified by counting the occurrences of each token in the exploded DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bb1c8fe",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>work</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>benefit</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>people</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>culture</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>life</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>balance</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pay</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>opportunity</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mastercard</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>employee</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lot</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>team</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>x000d</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>place</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>environment</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>401k</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>time</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>career</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>day</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>match</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>growth</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>learn</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compensation</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>apt</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>grow</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>year</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>new</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           token  count\n",
       "0           work    653\n",
       "1          great    460\n",
       "2           good    391\n",
       "3        benefit    324\n",
       "4        company    260\n",
       "5         people    229\n",
       "6        culture    211\n",
       "7           life    184\n",
       "8        balance    172\n",
       "9            pay    159\n",
       "10   opportunity    144\n",
       "11    mastercard    134\n",
       "12      employee    112\n",
       "13           lot    108\n",
       "14          team    106\n",
       "15         x000d    102\n",
       "16         place     94\n",
       "17   environment     91\n",
       "18          401k     91\n",
       "19          time     84\n",
       "20        career     73\n",
       "21           day     72\n",
       "22         match     63\n",
       "23        growth     62\n",
       "24         learn     60\n",
       "25  compensation     60\n",
       "26           apt     59\n",
       "27          grow     59\n",
       "28          year     58\n",
       "29           new     58"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liked_common_tokens = df_liked_exploded[\"token\"].value_counts().to_frame().reset_index().head(30)\n",
    "df_liked_common_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08763cd",
   "metadata": {},
   "source": [
    "### What did employees dislike about working at MasterCard?\n",
    "\n",
    "We can repeat the same process for the disliked column to identify the most common tokens in that column as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c6118e5",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_disliked_text</th>\n",
       "      <th>review_disliked_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101108831</td>\n",
       "      <td>only the people who is master</td>\n",
       "      <td>[people, master]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101220670</td>\n",
       "      <td>Like any fast-growing company, there have been...</td>\n",
       "      <td>[like, fast, grow, company, grow, pain, adapt,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100991760</td>\n",
       "      <td>The pay is not competitive compared with other...</td>\n",
       "      <td>[pay, competitive, compare, consulting, firm, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100092071</td>\n",
       "      <td>Some of the upper management is bias. For exam...</td>\n",
       "      <td>[upper, management, bias, example, 8, promotio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100155384</td>\n",
       "      <td>Where to begin? Mastercard is the poster child...</td>\n",
       "      <td>[begin, mastercard, poster, child, corporate, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                               review_disliked_text  \\\n",
       "0  101108831                      only the people who is master   \n",
       "1  101220670  Like any fast-growing company, there have been...   \n",
       "2  100991760  The pay is not competitive compared with other...   \n",
       "3  100092071  Some of the upper management is bias. For exam...   \n",
       "4  100155384  Where to begin? Mastercard is the poster child...   \n",
       "\n",
       "                              review_disliked_tokens  \n",
       "0                                   [people, master]  \n",
       "1  [like, fast, grow, company, grow, pain, adapt,...  \n",
       "2  [pay, competitive, compare, consulting, firm, ...  \n",
       "3  [upper, management, bias, example, 8, promotio...  \n",
       "4  [begin, mastercard, poster, child, corporate, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lists = []\n",
    "\n",
    "# parser is the dependency parser\n",
    "# ner is the named entity recognizer\n",
    "for doc in nlp.pipe(df[\"review_disliked_text\"], disable=[\"parser\", \"ner\"]):\n",
    "    token_lists.append(\n",
    "        [\n",
    "            token.lemma_.lower()\n",
    "            for token in doc\n",
    "            if not token.is_stop and not token.is_punct and not token.is_space\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df[\"review_disliked_tokens\"] = token_lists\n",
    "\n",
    "df[[\"review_id\", \"review_disliked_text\", \"review_disliked_tokens\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17d6a504",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101108831</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101108831</td>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101220670</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101220670</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101220670</td>\n",
       "      <td>grow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id   token\n",
       "0  101108831  people\n",
       "1  101108831  master\n",
       "2  101220670    like\n",
       "3  101220670    fast\n",
       "4  101220670    grow"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explode disliked_tokens so each token becomes its own row\n",
    "df_disliked_exploded = df[[\"review_id\", \"review_disliked_tokens\"]].explode(\"review_disliked_tokens\").reset_index(drop=True)\n",
    "df_disliked_exploded = df_disliked_exploded.rename(columns={\"review_disliked_tokens\": \"token\"})\n",
    "\n",
    "# Inspect result\n",
    "df_disliked_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c3dc689",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>work</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>company</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>management</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>team</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>people</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mastercard</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>employee</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x000d</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>office</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lot</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>year</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>culture</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>manager</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>good</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>like</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>slow</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hour</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pay</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>leadership</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>new</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>high</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>change</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>process</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>job</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lack</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>long</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tech</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>con</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  count\n",
       "0         work    383\n",
       "1      company    254\n",
       "2   management    176\n",
       "3         team    166\n",
       "4       people    165\n",
       "5         time    136\n",
       "6   mastercard    121\n",
       "7     employee    117\n",
       "8        x000d    115\n",
       "9       office    113\n",
       "10         lot    113\n",
       "11        year     99\n",
       "12     culture     98\n",
       "13     manager     94\n",
       "14        good     89\n",
       "15        like     88\n",
       "16        slow     84\n",
       "17        hour     80\n",
       "18         day     78\n",
       "19         pay     78\n",
       "20  leadership     74\n",
       "21         new     74\n",
       "22        high     72\n",
       "23      change     72\n",
       "24     process     69\n",
       "25         job     68\n",
       "26        lack     67\n",
       "27        long     67\n",
       "28        tech     64\n",
       "29         con     62"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disliked_common_tokens = df_disliked_exploded[\"token\"].value_counts().to_frame().reset_index().head(30)\n",
    "df_disliked_common_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
